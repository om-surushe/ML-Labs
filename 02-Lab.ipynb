{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorisation techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 : Tokenization : A sentence is represted as list of constituent words. This step is done for all input sentences\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sents = ['coronavirus is a highly infectious disease',\n",
    "'coronavirus affects older people the most', \n",
    "'older people are at high risk due to this disease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0]\n",
      " [0 1 1 0 1 1 1 0 0 0 0 1 1 1 0 1 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['affects',\n",
       " 'are',\n",
       " 'at',\n",
       " 'coronavirus',\n",
       " 'disease',\n",
       " 'due',\n",
       " 'high',\n",
       " 'highly',\n",
       " 'infectious',\n",
       " 'is',\n",
       " 'most',\n",
       " 'older',\n",
       " 'people',\n",
       " 'risk',\n",
       " 'the',\n",
       " 'this',\n",
       " 'to']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(sents)\n",
    "\n",
    "#Step 2 :Vocabulary Creation\n",
    "\n",
    "print(X.toarray())\n",
    "sorted(cv.vocabulary_.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 11)\t1\n",
      "  (1, 12)\t1\n",
      "  (1, 14)\t1\n",
      "  (1, 10)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 11)\t1\n",
      "  (2, 12)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 13)\t1\n",
      "  (2, 5)\t1\n",
      "  (2, 16)\t1\n",
      "  (2, 15)\t1\n"
     ]
    }
   ],
   "source": [
    "#Step 3 : Sparse Matrix Creation\n",
    "\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               TF-IDF\n",
      "infectious   0.490479\n",
      "highly       0.490479\n",
      "is           0.490479\n",
      "coronavirus  0.373022\n",
      "disease      0.373022\n",
      "older        0.000000\n",
      "this         0.000000\n",
      "the          0.000000\n",
      "risk         0.000000\n",
      "people       0.000000\n",
      "affects      0.000000\n",
      "most         0.000000\n",
      "are          0.000000\n",
      "high         0.000000\n",
      "due          0.000000\n",
      "at           0.000000\n",
      "to           0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\omsur\\OneDrive\\Documents\\Python\\Academics\\ML\\ML-acad\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "#transform the data\n",
    "transformed = tfidf.fit_transform(sents)\n",
    "# print(transformed)\n",
    "df = pd.DataFrame(transformed[0].T.todense(),\n",
    "index=tfidf.get_feature_names(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above output word infectious is more important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings_dict={}\n",
    "with open('./glove.6B.50d.txt','rb') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13175 , -0.25517 , -0.067915,  0.26193 , -0.26155 ,  0.23569 ,\n",
       "        0.13077 , -0.011801,  1.7659  ,  0.20781 ,  0.26198 , -0.16428 ,\n",
       "       -0.84642 ,  0.020094,  0.070176,  0.39778 ,  0.15278 , -0.20213 ,\n",
       "       -1.6184  , -0.54327 , -0.17856 ,  0.53894 ,  0.49868 , -0.10171 ,\n",
       "        0.66265 , -1.7051  ,  0.057193, -0.32405 , -0.66835 ,  0.26654 ,\n",
       "        2.842   ,  0.26844 , -0.59537 , -0.5004  ,  1.5199  ,  0.039641,\n",
       "        1.6659  ,  0.99758 , -0.5597  , -0.70493 , -0.0309  , -0.28302 ,\n",
       "       -0.13564 ,  0.6429  ,  0.41491 ,  1.2362  ,  0.76587 ,  0.97798 ,\n",
       "        0.58507 , -0.30176 ], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict[b'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'health',\n",
       " b'care',\n",
       " b'medical',\n",
       " b'welfare',\n",
       " b'prevention',\n",
       " b'education',\n",
       " b'public',\n",
       " b'poor',\n",
       " b'healthcare',\n",
       " b'needs']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_closest_embeddings(embedding):\n",
    "    return sorted(embeddings_dict.keys(), key=lambda word: \n",
    "spatial.distance.euclidean(embeddings_dict[word], embedding))\n",
    "\n",
    "find_closest_embeddings(embeddings_dict[b'health'])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['coronavirus', 'is', 'a', 'highly', 'infectious', 'disease'],\n",
       " ['coronavirus', 'affects', 'older', 'people', 'the', 'most'],\n",
       " ['older',\n",
       "  'people',\n",
       "  'are',\n",
       "  'at',\n",
       "  'high',\n",
       "  'risk',\n",
       "  'due',\n",
       "  'to',\n",
       "  'this',\n",
       "  'disease']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = [sent.split() for sent in sents]\n",
    "sents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ML-acad': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77569a8a16e3f27897e630428fb498178724fb45584ce3a49e47268bb48fa7b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
